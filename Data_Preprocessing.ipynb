{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7e55533",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paz.backend.image import load_image, show_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc504f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "from paz.applications import HaarCascadeFrontalFace, MiniXceptionFER\n",
    "import paz.processors as pr\n",
    "\n",
    "class EmotionDetector(pr.Processor):\n",
    "    def __init__(self):\n",
    "        super(EmotionDetector, self).__init__()\n",
    "        self.detect = HaarCascadeFrontalFace(draw=False)\n",
    "        self.crop = pr.CropBoxes2D()\n",
    "        self.classify = MiniXceptionFER()\n",
    "        self.draw = pr.DrawBoxes2D(self.classify.class_names)\n",
    "\n",
    "    def call(self, image):\n",
    "        boxes2D = self.detect(image)['boxes2D']\n",
    "        cropped_images = self.crop(image, boxes2D)\n",
    "        for cropped_image, box2D in zip(cropped_images, boxes2D):\n",
    "            box2D.class_name = self.classify(cropped_image)['class_name']\n",
    "        return self.draw(image, boxes2D)\n",
    "        \n",
    "detect = EmotionDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d659c009",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_numbers = [\"%05d\" % i for i in range(1, 3000, 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e24bf65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./DMD_Frames/GA1S1/Face/00001.png\n",
      "./DMD_Frames/GA1S1/Face/00101.png\n",
      "./DMD_Frames/GA1S1/Face/00201.png\n",
      "./DMD_Frames/GA1S1/Face/00301.png\n",
      "./DMD_Frames/GA1S1/Face/00401.png\n",
      "./DMD_Frames/GA1S1/Face/00501.png\n",
      "./DMD_Frames/GA1S1/Face/00601.png\n",
      "./DMD_Frames/GA1S1/Face/00701.png\n",
      "./DMD_Frames/GA1S1/Face/00801.png\n",
      "./DMD_Frames/GA1S1/Face/00901.png\n",
      "./DMD_Frames/GA1S1/Face/01001.png\n",
      "./DMD_Frames/GA1S1/Face/01101.png\n",
      "./DMD_Frames/GA1S1/Face/01201.png\n",
      "./DMD_Frames/GA1S1/Face/01301.png\n",
      "./DMD_Frames/GA1S1/Face/01401.png\n",
      "./DMD_Frames/GA1S1/Face/01501.png\n",
      "./DMD_Frames/GA1S1/Face/01601.png\n",
      "./DMD_Frames/GA1S1/Face/01701.png\n",
      "./DMD_Frames/GA1S1/Face/01801.png\n",
      "./DMD_Frames/GA1S1/Face/01901.png\n",
      "./DMD_Frames/GA1S1/Face/02001.png\n",
      "./DMD_Frames/GA1S1/Face/02101.png\n",
      "./DMD_Frames/GA1S1/Face/02201.png\n",
      "./DMD_Frames/GA1S1/Face/02301.png\n",
      "./DMD_Frames/GA1S1/Face/02401.png\n",
      "./DMD_Frames/GA1S1/Face/02501.png\n",
      "./DMD_Frames/GA1S1/Face/02601.png\n",
      "./DMD_Frames/GA1S1/Face/02701.png\n",
      "./DMD_Frames/GA1S1/Face/02801.png\n",
      "./DMD_Frames/GA1S1/Face/02901.png\n"
     ]
    }
   ],
   "source": [
    "for i in image_numbers:\n",
    "    path = './DMD_Frames/GA1S1/Face/' + i + '.png'\n",
    "    print(path)\n",
    "    image = load_image(path)\n",
    "    show_image(detect.call(image))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bc2309",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

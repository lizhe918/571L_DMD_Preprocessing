{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7589202c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paz.backend.image import load_image, show_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e7ba9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paz.applications import HaarCascadeFrontalFace, MiniXceptionFER\n",
    "import paz.processors as pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea4f6dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paz.backend.image.image import crop_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1292543",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paz.processors.detection import CropBoxes2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7a60a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect = HaarCascadeFrontalFace(draw=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ebbd34d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop = CropBoxes2D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86d9bd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './DMD_Frames/GA1S1/Face/02000.png'\n",
    "image = load_image(path)\n",
    "show_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "044976ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference = detect(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3af9f329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image': array([[[38, 55, 47],\n",
      "        [38, 55, 47],\n",
      "        [40, 55, 48],\n",
      "        ...,\n",
      "        [74, 78, 66],\n",
      "        [75, 80, 67],\n",
      "        [75, 80, 67]],\n",
      "\n",
      "       [[38, 55, 47],\n",
      "        [38, 55, 47],\n",
      "        [40, 55, 48],\n",
      "        ...,\n",
      "        [71, 78, 66],\n",
      "        [72, 79, 68],\n",
      "        [74, 80, 69]],\n",
      "\n",
      "       [[40, 57, 49],\n",
      "        [39, 56, 48],\n",
      "        [42, 57, 49],\n",
      "        ...,\n",
      "        [73, 77, 66],\n",
      "        [73, 77, 66],\n",
      "        [73, 77, 66]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 7, 21, 18],\n",
      "        [ 7, 21, 18],\n",
      "        [ 7, 21, 18],\n",
      "        ...,\n",
      "        [63, 82, 76],\n",
      "        [64, 83, 77],\n",
      "        [65, 85, 78]],\n",
      "\n",
      "       [[ 7, 21, 18],\n",
      "        [ 7, 21, 18],\n",
      "        [ 7, 21, 18],\n",
      "        ...,\n",
      "        [63, 82, 76],\n",
      "        [63, 82, 76],\n",
      "        [62, 81, 75]],\n",
      "\n",
      "       [[ 7, 21, 18],\n",
      "        [ 7, 21, 18],\n",
      "        [ 7, 21, 18],\n",
      "        ...,\n",
      "        [63, 82, 76],\n",
      "        [62, 81, 75],\n",
      "        [61, 80, 73]]], dtype=uint8), 'boxes2D': [Box2D(534, 250, 741, 457, 1.0, Face)]}\n"
     ]
    }
   ],
   "source": [
    "print(inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bae77a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes2D = inference['boxes2D']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b324f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_images = crop(image, boxes2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a838214",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(cropped_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9406d710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "classify = MiniXceptionFER()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64758e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion = classify(cropped_images[0])['class_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f13a4fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral\n"
     ]
    }
   ],
   "source": [
    "print(emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c67218",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
